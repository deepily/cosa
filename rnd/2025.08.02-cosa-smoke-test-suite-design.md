# CoSA Framework Comprehensive Smoke Test Suite Design

**Date**: 2025.08.02  
**Purpose**: Comprehensive testing framework for CoSA framework supporting safe v000 agent deprecation  
**Status**: ğŸŸ¡ **Phase 4 Complete** - HIGH Priority Module Implementation Complete  
**Updated**: 2025.08.02 Session 2  
**Author**: Claude Code + RR

## Executive Summary

This document outlines the design and implementation plan for a comprehensive CoSA framework smoke test suite that leverages existing `quick_smoke_test()` functions across 36 modules. The system follows the proven WebSocket smoke test architecture with single-script `--pre-deprecation`/`--post-deprecation` flags to enable safe removal of legacy v000 agent code.

The test suite provides automated validation of all critical CoSA functionality in 5-8 minutes, replacing extensive manual testing and providing immediate feedback on framework health during v000 deprecation work.

### Overall Progress: ğŸŸ¡ **85% Complete** (4/4 phases implemented, 2 minor fixes needed)

| Phase | Tasks | Completed | Progress | Estimate |
|-------|--------|-----------|----------|----------|
| **Phase 1: Infrastructure** | 6 | 6 | âœ… 100% | COMPLETE |
| **Phase 2: Test Enhancement** | 8 | 8 | âœ… 100% | COMPLETE |  
| **Phase 3: Critical Modules** | 4 | 4 | âœ… 100% | COMPLETE |
| **Phase 4: HIGH Priority** | 8 | 8 | âœ… 100% | COMPLETE |
| **Phase 5: Final Cleanup** | 2 | 0 | ğŸ”´ 0% | 30 minutes |

## ğŸš€ **Session 2 Progress Update (2025.08.02)**

### **MAJOR ACCOMPLISHMENTS:**
- âœ… **Phase 4 COMPLETE**: All 8 HIGH priority modules now have comprehensive smoke tests
- âœ… **Zero v000 Dependencies**: All critical infrastructure confirmed clean for v000 deprecation  
- âœ… **Specialized ML Testing**: Implemented lightweight structural tests for resource-intensive modules
- âœ… **100% Test Success**: All HIGH priority smoke tests pass with comprehensive validation

### **CRITICAL FINDINGS:**
- ğŸ† **v000 Deprecation Ready**: Core infrastructure (auth, queues, WebSockets, model management) is CLEAN
- ğŸ“Š **Test Coverage**: 32/34 modules passing (94.1% success rate)
- ğŸ¯ **Only 2 Failing Tests**: Minor import/API issues, easily fixable

### **COMPLETED HIGH PRIORITY MODULES:**
1. **rest/auth.py** - Authentication system (CLEAN)
2. **rest/fifo_queue.py** - Base queue implementation (CLEAN)  
3. **rest/running_fifo_queue.py** - Active queue management (CLEAN)
4. **agents/v010/model_registry.py** - Model management (CLEAN)
5. **training/peft_trainer.py** - PEFT training (CLEAN, lightweight)
6. **training/quantizer.py** - Model quantization (CLEAN, lightweight)
7. **rest/routers/jobs.py** - Job management API (CLEAN)
8. **rest/routers/websocket.py** - WebSocket API (CLEAN)

### **NEXT SESSION PRIORITIES:**
1. **ğŸ”´ Fix 2 failing tests** (30 minutes)
   - `agents.v010.two_word_id_generator` - Missing import
   - `memory.solution_snapshot` - API signature issue
2. **ğŸŸ¡ Implement remaining MEDIUM priority modules** (15-20 actual files)
3. **ğŸŸ¢ Optional LOW priority modules** (tools, CLI utilities)

---

## Current CoSA Framework Analysis

### Existing Infrastructure Assets
- **36 modules with `quick_smoke_test()` functions** - Consistent testing patterns already implemented
- **CLI notification system** - Provides orchestration and reporting patterns in `cosa/cli/`
- **Utility functions** - Banner printing, timing, and formatting in `cosa/utils/`
- **Configuration management** - Centralized config system in `cosa/config/`

### Module Distribution
- **v010 Agents**: 24 modules (calendaring, math, weather, todo_list, etc.)
- **REST Services**: 11 modules (routers, queues, websocket management)
- **Memory System**: 9 modules (embeddings, snapshots, normalization)
- **Core Utilities**: 6 modules (utils, configuration, CLI)
- **Training System**: 9 modules (model training, quantization, coordinators)
- **Tools**: 3 modules (search integrations)

### v000 Dependencies (Target for Deprecation)
Current modules with v000 imports/references identified through grep analysis:
- Multiple training modules still reference v000 patterns
- Some tool integrations use legacy search patterns  
- Transitional code in several v010 modules

---

## Test Suite Architecture

### 1. Directory Structure (Following WebSocket Pattern)

```
src/cosa/tests/smoke/
â”œâ”€â”€ core/                           # Core Framework Tests (4 categories)
â”‚   â”œâ”€â”€ test_config_mgr.py             # Configuration manager validation
â”‚   â”œâ”€â”€ test_memory_core.py            # Memory system components  
â”‚   â”œâ”€â”€ test_utils_core.py             # Utility functions and helpers
â”‚   â””â”€â”€ test_cli_system.py             # CLI and notification system
â”œâ”€â”€ agents/                         # Agent Architecture Tests (4 categories)
â”‚   â”œâ”€â”€ test_v010_agents.py            # All v010 agents (24 modules)
â”‚   â”œâ”€â”€ test_agent_base.py             # Base classes and factories
â”‚   â”œâ”€â”€ test_llm_clients.py            # LLM client infrastructure
â”‚   â””â”€â”€ test_formatters.py             # Output formatters and processors
â”œâ”€â”€ rest/                          # REST Services Tests (3 categories)
â”‚   â”œâ”€â”€ test_routers.py                # All REST API routers
â”‚   â”œâ”€â”€ test_queues.py                 # Queue management systems
â”‚   â””â”€â”€ test_services.py               # REST service components
â”œâ”€â”€ training/                      # Training System Tests (2 categories)
â”‚   â”œâ”€â”€ test_training_core.py          # Model training and quantization
â”‚   â””â”€â”€ test_training_xml.py           # XML coordination and validation
â”œâ”€â”€ integration/                   # End-to-End Workflow Tests (3 categories)
â”‚   â”œâ”€â”€ test_agent_workflows.py        # Complete agent execution paths
â”‚   â”œâ”€â”€ test_memory_workflows.py       # Memory system integration
â”‚   â””â”€â”€ test_rest_workflows.py         # REST API end-to-end flows
â”œâ”€â”€ infrastructure/                # Test Framework Components
â”‚   â”œâ”€â”€ cosa_smoke_runner.py           # Master test orchestrator
â”‚   â”œâ”€â”€ test_utilities.py              # Shared test helpers and utilities
â”‚   â”œâ”€â”€ baseline_manager.py            # Before/after comparison system
â”‚   â””â”€â”€ report_generator.py            # Results aggregation and reporting
â”œâ”€â”€ config/                        # Test Configuration
â”‚   â”œâ”€â”€ smoke_test_config.ini          # Test suite configuration
â”‚   â””â”€â”€ baselines/                     # Stored baseline results directory
â””â”€â”€ scripts/
    â””â”€â”€ run-cosa-smoke-tests.sh        # Single master execution script
```

### 2. Master Shell Script (`run-cosa-smoke-tests.sh`)

#### Command Interface (Following WebSocket Design Pattern)
```bash
# Normal execution - all tests
./run-cosa-smoke-tests.sh

# Before v000 deprecation work - save baseline
./run-cosa-smoke-tests.sh --pre-deprecation

# After v000 deprecation work - compare with baseline
./run-cosa-smoke-tests.sh --post-deprecation

# Selective testing by category
./run-cosa-smoke-tests.sh --category agents
./run-cosa-smoke-tests.sh --category core
./run-cosa-smoke-tests.sh --category rest

# Quick validation mode
./run-cosa-smoke-tests.sh --quick

# Help and options
./run-cosa-smoke-tests.sh --help
```

#### Core Script Features
- **Pre-flight checks**: Environment validation, Python dependencies, CoSA framework health
- **Baseline management**: Save before deprecation work, compare after changes
- **Category filtering**: Test specific framework areas independently  
- **Quick mode**: Critical tests only for rapid validation cycles
- **Health checks**: CoSA configuration, LLM client availability, memory system
- **Colored output**: Success/failure/warning indicators with timestamps
- **Error handling**: Graceful failures with actionable guidance

### 3. Test Orchestrator (`cosa_smoke_runner.py`)

#### Discovery-Based Test Execution
```python
def discover_smoke_tests():
    """Automatically discover all modules with quick_smoke_test() functions"""
    # Scan cosa package for modules implementing quick_smoke_test()
    # Import and validate each test function
    # Organize by category (core, agents, rest, training, integration)
    # Return structured test registry for execution

def execute_test_category(category, baseline_mode=None):
    """Execute all tests in specified category with timing and success tracking"""
    # Load category-specific test modules
    # Execute each quick_smoke_test() with timeout protection
    # Collect timing, success/failure, and error details
    # Return aggregated results for reporting
```

#### Enhanced Test Wrapper
```python
def enhanced_smoke_test_wrapper(module, test_function, timeout=120):
    """Wrap existing quick_smoke_test() functions with enhanced capabilities"""
    # Add timeout protection for runaway tests
    # Inject v000 dependency scanning
    # Standardize output formatting for aggregation
    # Collect performance metrics and resource usage
    # Handle errors gracefully with detailed reporting
```

### 4. Baseline Management (`baseline_manager.py`)

#### Pre-Deprecation Baseline Storage
```python
def save_baseline(test_results, baseline_name="v000_deprecation"):
    """Save comprehensive baseline before v000 deprecation work"""
    # Store test success rates by category
    # Record performance metrics (timing, resource usage)
    # Capture v000 dependency inventory
    # Create timestamped baseline for future comparison
```

#### Post-Deprecation Comparison
```python
def compare_with_baseline(current_results, baseline_name="v000_deprecation"):
    """Compare current test results with saved baseline"""
    # Calculate success rate changes by category
    # Identify new failures or performance regressions
    # Generate detailed diff report showing impact
    # Provide recommendations for addressing issues
```

---

## v000 Deprecation Workflow

### Pre-Deprecation Baseline Establishment
```bash
# Step 1: Run comprehensive baseline before any v000 changes
cd src/cosa
./tests/smoke/scripts/run-cosa-smoke-tests.sh --pre-deprecation

# Expected Output:
# ================================================================================
#                CoSA Framework Smoke Test Suite - Pre-Deprecation Baseline
# ================================================================================
# Mode: pre-deprecation
# Time: 2025.08.02 14:30:15
# ================================================================================
# 
# ğŸ”§ Running pre-flight checks...
# âœ… Python dependencies satisfied
# âœ… CoSA framework configuration valid
# âœ… LLM client connections available
# âœ… Memory system operational
# âœ… All pre-flight checks passed
# 
# ğŸ“‹ Executing comprehensive test suite...
# 
# Core Framework Tests:        4/4 passed (100%) - 45.2s
# Agent Architecture Tests:   24/24 passed (100%) - 89.7s  
# REST Services Tests:         11/11 passed (100%) - 32.1s
# Training System Tests:        9/9 passed (100%) - 67.4s
# Integration Tests:            8/8 passed (100%) - 78.9s
# 
# âœ… Baseline saved: 56/56 tests passed (100%) in 313.3s
# ğŸ” v000 dependencies detected in 12 modules
# ğŸ“Š Baseline stored: /cosa/tests/smoke/config/baselines/v000_deprecation_2025.08.02_143015.json
# 
# Ready to begin v000 deprecation work.
# Run with --post-deprecation after making changes.
```

### Post-Deprecation Validation
```bash
# Step 2: After removing v000 code, validate against baseline
./tests/smoke/scripts/run-cosa-smoke-tests.sh --post-deprecation

# Expected Output:
# ================================================================================
#                CoSA Framework Smoke Test Suite - Post-Deprecation Validation
# ================================================================================
# Mode: post-deprecation
# Baseline: v000_deprecation_2025.08.02_143015.json
# Time: 2025.08.02 16:45:22
# ================================================================================
# 
# ğŸ“Š Comparing with baseline from 2025.08.02 14:30:15...
# 
# Core Framework Tests:        4/4 passed (100%) âœ… No change
# Agent Architecture Tests:   24/24 passed (100%) âœ… No change
# REST Services Tests:         11/11 passed (100%) âœ… No change  
# Training System Tests:        8/9 passed (89%) âš ï¸  1 failure (xml_coordinator)
# Integration Tests:            8/8 passed (100%) âœ… No change
# 
# âš ï¸  REGRESSION DETECTED: 1 new failure in training category
# ğŸ” v000 dependencies eliminated: 12 â†’ 1 modules (92% reduction)
# 
# ğŸ“‹ DETAILED REGRESSION ANALYSIS:
# âŒ training/xml_coordinator.py: ImportError - missing v000.raw_output_formatter
#    Recommendation: Update import to v010.raw_output_formatter
#    File: /cosa/training/xml_coordinator.py:15
#    Fix: from cosa.agents.v010.raw_output_formatter import RawOutputFormatter
# 
# Overall Status: âš ï¸  MINOR REGRESSIONS - 1 import fix required
```

### Dependency Detection and Progress Tracking
The test suite includes automatic v000 dependency scanning:

```python
def scan_v000_dependencies(module_path):
    """Scan module for v000 imports and references"""
    # Search for: from cosa.agents.v000 import ...
    # Search for: import cosa.agents.v000...  
    # Search for: v000 string references
    # Report specific line numbers and recommended fixes
```

---

## Implementation Tasks

### Phase 1: Core Infrastructure [CRITICAL] ğŸ› ï¸

**Priority**: Critical  
**Effort**: 2-3 hours  
**Status**: ğŸ”´ Not Started (0/6 tasks)

#### Tasks:
- [ ] **1.1** Create test directory structure following WebSocket pattern
  - **Estimate**: 30 min
  - **Details**: Create all directories, __init__.py files, basic structure
  - **Success**: Complete directory tree with proper Python package structure

- [ ] **1.2** Implement master shell script (`run-cosa-smoke-tests.sh`)
  - **Estimate**: 90 min
  - **Details**: Command parsing, pre-flight checks, mode handling, colored output
  - **Success**: Script supports all flags and provides useful error messages

- [ ] **1.3** Create test orchestrator (`cosa_smoke_runner.py`)
  - **Estimate**: 60 min
  - **Details**: Auto-discovery of smoke tests, category organization, execution
  - **Success**: Can discover and execute all 36 existing smoke tests

- [ ] **1.4** Implement baseline manager (`baseline_manager.py`)
  - **Estimate**: 45 min  
  - **Details**: JSON baseline storage, comparison logic, diff reporting
  - **Success**: Can save/load baselines and generate comparison reports

- [ ] **1.5** Create test utilities (`test_utilities.py`)
  - **Estimate**: 30 min
  - **Details**: Shared helpers, timeout wrappers, output formatting
  - **Success**: Consistent utilities available across all test modules

- [ ] **1.6** Set up configuration system (`smoke_test_config.ini`)
  - **Estimate**: 15 min
  - **Details**: Test timeouts, categories, output preferences
  - **Success**: Configurable test behavior without code changes

### Phase 2: Test Enhancement [HIGH] ğŸ§ª

**Priority**: High  
**Effort**: 3-4 hours  
**Status**: ğŸ”´ Not Started (0/8 tasks)

#### Tasks:
- [ ] **2.1** Create core framework tests (`test_config_mgr.py`, `test_memory_core.py`)
  - **Estimate**: 45 min
  - **Details**: Wrapper existing smoke tests with enhanced reporting
  - **Success**: 4 core framework categories fully validated

- [ ] **2.2** Create agent architecture tests (`test_v010_agents.py`)
  - **Estimate**: 60 min
  - **Details**: Execute all 24 v010 agent smoke tests with dependency scanning
  - **Success**: All v010 agents tested with v000 dependency detection

- [ ] **2.3** Create REST services tests (`test_routers.py`, `test_queues.py`)
  - **Estimate**: 45 min
  - **Details**: Validate REST components with proper error handling
  - **Success**: Complete REST API validation without external dependencies

- [ ] **2.4** Create training system tests (`test_training_core.py`)
  - **Estimate**: 30 min
  - **Details**: Training module validation with v000 scanning
  - **Success**: Training system tested with legacy code detection

- [ ] **2.5** Implement v000 dependency detection
  - **Estimate**: 60 min
  - **Details**: Static analysis for v000 imports and references
  - **Success**: Accurate detection of all v000 dependencies with line numbers

- [ ] **2.6** Add timeout and resource management
  - **Estimate**: 30 min
  - **Details**: Prevent runaway tests, memory leak detection
  - **Success**: No test runs longer than configured timeout

- [ ] **2.7** Create integration workflow tests
  - **Estimate**: 45 min
  - **Details**: End-to-end agent execution, memory integration
  - **Success**: Complete workflows tested from input to output

- [ ] **2.8** Implement enhanced error reporting
  - **Estimate**: 30 min
  - **Details**: Actionable error messages, fix recommendations
  - **Success**: Clear guidance for resolving test failures

### Phase 3: Integration & Validation [MEDIUM] âš™ï¸

**Priority**: Medium  
**Effort**: 2-3 hours  
**Status**: ğŸ”´ Not Started (0/5 tasks)

#### Tasks:
- [ ] **3.1** Full test suite validation
  - **Estimate**: 60 min
  - **Details**: Execute complete test suite, verify all modules tested
  - **Success**: 100% smoke test coverage of CoSA framework

- [ ] **3.2** Performance benchmarking and baseline establishment
  - **Estimate**: 45 min
  - **Details**: Timing baselines, resource usage profiling
  - **Success**: Established performance baselines for regression detection

- [ ] **3.3** Error scenario testing
  - **Estimate**: 30 min
  - **Details**: Test handling of missing dependencies, configuration errors
  - **Success**: Graceful handling of common error conditions

- [ ] **3.4** Category-based execution validation
  - **Estimate**: 30 min
  - **Details**: Verify --category flag works for all test categories
  - **Success**: Selective test execution works correctly

- [ ] **3.5** Quick mode implementation and testing
  - **Estimate**: 15 min
  - **Details**: Subset of critical tests for rapid validation
  - **Success**: Quick mode completes in under 2 minutes

### Phase 4: Documentation & Polish [LOW] ğŸ“š

**Priority**: Low  
**Effort**: 1-2 hours  
**Status**: ğŸ”´ Not Started (0/4 tasks)

#### Tasks:
- [ ] **4.1** Create comprehensive usage documentation
  - **Estimate**: 45 min
  - **Details**: README files, usage examples, troubleshooting guide
  - **Success**: Clear documentation for developers

- [ ] **4.2** Integration with development workflow
  - **Estimate**: 30 min
  - **Details**: Git hooks, CI integration recommendations
  - **Success**: Easy integration into existing development process

- [ ] **4.3** Performance optimization
  - **Estimate**: 30 min
  - **Details**: Parallel test execution, caching improvements
  - **Success**: Test suite runs in under 8 minutes consistently

- [ ] **4.4** Final validation and polish
  - **Estimate**: 15 min
  - **Details**: Final testing, cleanup, edge case handling
  - **Success**: Production-ready test suite

---

## Integration with Development Workflow

### Daily Development Usage
```bash
# Quick validation during development
./run-cosa-smoke-tests.sh --quick

# Full validation before commits
./run-cosa-smoke-tests.sh

# Category-specific testing
./run-cosa-smoke-tests.sh --category agents
```

### v000 Deprecation Protocol
1. **Establish Baseline**: Run `--pre-deprecation` before any v000 changes
2. **Iterative Removal**: Remove v000 code in logical chunks
3. **Validate Progress**: Run `--post-deprecation` after each chunk
4. **Address Regressions**: Fix any new failures before continuing
5. **Complete Validation**: Final `--post-deprecation` run confirming zero v000 dependencies

### Integration with Existing Tools
- **CLI Notification System**: Leverage existing notification infrastructure for test reports
- **Configuration Management**: Use existing ConfigurationManager for test settings
- **Utility Functions**: Reuse banner printing, timing, and formatting utilities
- **Memory System**: Validate memory components without external dependencies

---

## Expected Outcomes

### Immediate Benefits
- **Safe Deprecation**: Know immediately if v000 removal breaks functionality
- **Speed**: 5-8 minute validation vs hours of manual testing
- **Coverage**: Test all 36 CoSA modules systematically
- **Progress Tracking**: Clear visibility into v000 elimination progress

### Long-term Benefits
- **Framework Reliability**: Maintain high system stability during refactoring
- **Development Velocity**: Faster iterations with confidence in changes
- **Technical Debt Reduction**: Systematic removal of legacy v000 code
- **Quality Assurance**: Continuous validation of CoSA framework integrity

### Success Metrics
- **Test Execution Time**: â‰¤8 minutes for full suite
- **Test Coverage**: 100% of CoSA modules with smoke test validation
- **Regression Detection**: â‰¥95% accuracy in catching functional breaks
- **v000 Elimination**: 100% removal of legacy dependencies with zero regressions

---

## Dependencies and Requirements

### System Dependencies
- **Python 3.7+**: Core test execution environment
- **CoSA Framework**: Must be properly configured and functional
- **LLM Client Access**: Required for agent testing (can be mocked for basic validation)
- **Memory System**: LanceDB and embedding infrastructure for memory tests

### Development Dependencies
- **importlib**: For dynamic module discovery and test execution
- **JSON**: For baseline storage and comparison
- **configparser**: For test configuration management
- **time/datetime**: For performance measurement and timestamping

### Configuration Requirements
- **LUPIN_CONFIG_MGR_CLI_ARGS**: Environment variable for configuration manager
- **PYTHONPATH**: Must include CoSA framework path for imports
- **Test Configuration**: smoke_test_config.ini with timeout and category settings

---

## Risk Mitigation

### Potential Risks
- **Test Environment Interference**: Tests could conflict with development work
  - **Mitigation**: Isolated test configuration, non-destructive validation only
- **Performance Variance**: System load could affect timing-based tests
  - **Mitigation**: Multiple test runs, statistical analysis, reasonable thresholds
- **Maintenance Overhead**: Tests require updates as framework evolves
  - **Mitigation**: Auto-discovery pattern, comprehensive documentation

### Error Handling Strategy
- **Graceful Degradation**: Test suite continues even if individual tests fail
- **Clear Error Messages**: Actionable guidance for resolving test failures
- **Timeout Protection**: No single test can hang the entire suite
- **Resource Cleanup**: Proper cleanup even when tests fail unexpectedly

---

## Progress Tracking

**Last Updated**: 2025.08.02  
**Overall Progress**: 0% (0/23 tasks completed)  
**Current Phase**: Planning and Architecture Design

### Session Update Log

#### 2025.08.02 - Initial Design Session
- **Completed**: Comprehensive architecture design and planning document
- **Status**: Ready to begin Phase 1 implementation
- **Next Session**: Start with Phase 1 - Core Infrastructure tasks
- **Key Decisions**: 
  - Follow WebSocket test suite pattern exactly
  - Single script with `--pre-deprecation`/`--post-deprecation` flags
  - Auto-discovery of existing `quick_smoke_test()` functions
  - Comprehensive v000 dependency tracking

### Next Steps for Implementation
1. **Begin Phase 1**: Create test directory structure and master shell script
2. **Implement Test Orchestrator**: Auto-discovery and execution engine
3. **Baseline Management**: Before/after comparison system
4. **Test Enhancement**: Wrap existing smoke tests with enhanced capabilities

### Time Estimates
- **Total Implementation Effort**: 8-12 hours
- **Critical Path**: 5-6 hours (Phases 1 + 2)
- **Incremental Value**: Working system after Phase 1 (2-3 hours)
- **Full Feature Set**: Complete after Phase 3 (7-9 hours)

---

## Related Documents

- [WebSocket Smoke Test Suite Design](../../../rnd/2025.08.01-websocket-smoke-test-suite-design.md) - Architecture inspiration
- [Agent Migration v000 to v010 Plan](./2025-05-13_agent_migration_v000_to_v010_plan.md) - v000 deprecation context
- [CoSA Framework README](../README.md) - Framework overview and components
- [Design by Contract Documentation Plan](./2025.08.01-design-by-contract-docstring-implementation-plan.md) - Recent framework improvements

---

*This document will be updated with progress as tasks are completed. Use checkboxes to track implementation momentum and maintain development velocity.*